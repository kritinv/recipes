{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28af9f4c",
   "metadata": {},
   "source": [
    "# Weaviate Import\n",
    "\n",
    "This notebook is used to populate the `WeaviateBlogChunk` class.\n",
    "\n",
    "You can connect to Weaviate through local host, or create a free 14-day sandbox on [WCS](https://console.weaviate.cloud/)!\n",
    "\n",
    "1. (Option 1) Create a cluster on WCS and grab your cluster URL and auth key (if enabled)\n",
    "\n",
    "1. (Option 2) Run `docker-compose up -d` with the docker script in the file to start Weaviate locally on localhost:8080\n",
    "\n",
    "\n",
    "2. Make sure the `/blog` folder is in this directory (these are parsed from github.com/weaviate/weaviate-io -- feel free to drag and drop that folder in here to update the content).\n",
    "\n",
    "\n",
    "3. Run this notebook and the 1182 blog chunks will be loaded into Weaviate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1c926e",
   "metadata": {},
   "source": [
    "## Connect to Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf69ba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Weaviate and Connect to Client\n",
    "import weaviate\n",
    "import os\n",
    "\n",
    "\n",
    "WCD_CLUSTER_URL = os.getenv(\"WCD_CLUSTER_URL\")\n",
    "WCD_CLUSTER_KEY = os.getenv(\"WCD_CLUSTER_KEY\")\n",
    "OPENAI_KEY = os.getenv(\"OPENAI_KEY\")\n",
    "\n",
    "# client = weaviate.connect_to_local()  # Connect to local host\n",
    "\n",
    "# connect to your cluster on WCD\n",
    "client = weaviate.connect_to_weaviate_cloud(\n",
    "    cluster_url=WCD_CLUSTER_URL,  # Replace with your WCD URL\n",
    "    auth_credentials=weaviate.auth.AuthApiKey(WCD_CLUSTER_KEY),  # Replace with your WCD key\n",
    "    headers={\n",
    "        'X-OpenAI-Api-Key': OPENAI_KEY # Replace with your OpenAI API key\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bb10a5",
   "metadata": {},
   "source": [
    "## Create Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b209831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAUTION: Running this will delete the collection along with the objects\n",
    "\n",
    "# client.collections.delete_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3643f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate.classes.config as wvcc\n",
    "\n",
    "collection = client.collections.create(\n",
    "    name=\"WeaviateBlogChunk\",\n",
    "    vectorizer_config=wvcc.Configure.Vectorizer.text2vec_openai\n",
    "    (\n",
    "        model=\"ada\"\n",
    "    ),\n",
    "    properties=[\n",
    "            wvcc.Property(name=\"content\", data_type=wvcc.DataType.TEXT),\n",
    "            wvcc.Property(name=\"author\", data_type=wvcc.DataType.TEXT),\n",
    "      ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19336940",
   "metadata": {},
   "source": [
    "## Chunk Blogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a6788d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def chunk_list(lst, chunk_size):\n",
    "    \"\"\"Break a list into chunks of the specified size.\"\"\"\n",
    "    return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    \"\"\"Split text into sentences using regular expressions.\"\"\"\n",
    "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)\n",
    "    return [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "\n",
    "def read_and_chunk_index_files(main_folder_path):\n",
    "    \"\"\"Read index.md files from subfolders, split into sentences, and chunk every 5 sentences.\"\"\"\n",
    "    blog_chunks = []\n",
    "    for folder_name in os.listdir(main_folder_path):\n",
    "        subfolder_path = os.path.join(main_folder_path, folder_name)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            index_file_path = os.path.join(subfolder_path, 'index.mdx')\n",
    "            if os.path.isfile(index_file_path):\n",
    "                with open(index_file_path, 'r', encoding='utf-8') as file:\n",
    "                    content = file.read()\n",
    "                    sentences = split_into_sentences(content)\n",
    "                    sentence_chunks = chunk_list(sentences, 5)\n",
    "                    sentence_chunks = [' '.join(chunk) for chunk in sentence_chunks]\n",
    "                    blog_chunks.extend(sentence_chunks)\n",
    "    return blog_chunks\n",
    "\n",
    "# Example usage\n",
    "main_folder_path = '../data'\n",
    "blog_chunks = read_and_chunk_index_files(main_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed58c948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(blog_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ea97830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'---\\ntitle: ChatGPT for Generative Search\\nslug: generative-search\\nauthors: [zain, erika, connor]\\ndate: 2023-02-07\\ntags: [\\'search\\', \\'integrations\\']\\nimage: ./img/hero.png\\ndescription: \"Learn how you can customize Large Language Models prompt responses to your own data by leveraging vector databases.\"\\n---\\n![ChatGPT for Generative Search](./img/hero.png)\\n\\n<!-- truncate -->\\n\\nWhen OpenAI launched ChatGPT at the end of 2022, more than one million people had tried the model in just a week and that trend has only continued with monthly active users for the chatbot service reaching over 100 Million, quicker than any service before, as reported by [Reuters](https://www.reuters.com/technology/chatgpt-sets-record-fastest-growing-user-base-analyst-note-2023-02-01/) and [Yahoo Finance](https://finance.yahoo.com/news/chatgpt-on-track-to-surpass-100-million-users-faster-than-tiktok-or-instagram-ubs-214423357.html?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAFCTz2vosCcjWFstJGkvduTSNZJrxULx8EHwbTE8mF7EV-hAlWvmMe59ex94LHlkB40zlUMUPshv5Ggq1GxyY9oDQxtoLcc0GV2E-v-0DeGuZi7dtEJT9MZF5NvUe20V64ZCVNziFtJdWUL_AAxMFoCGFxT1duBiaPbfzwkjbyNQ). It wouldn’t be hyperbole to say that NLP and Generative Large Language Models (LLMs) have taken the world by storm. Though this was not the first AI chatbot that has been released to the public, what really surprised people about this particular service was the breadth and depth of knowledge it had and its ability to articulate that knowledge with human-like responses. Aside from this, the generative aspect of this model is also quite apparent as it can hallucinate situations and dream up vivid details to fill in descriptions when prompted to do so. This gives the chatbot service somewhat of a human-like “creativity” - which is what adds a wow factor to the user experience!\\n\\nGenerative LLMs like ChatGPT\\'s GPT-3 (Chat Generative Pre-trained Transformer) are trained on a huge corpora of open data from the internet - since the majority of general human knowledge is archived and accessible via the Internet, these models have a lot of training material to learn from.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_chunks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9261a1",
   "metadata": {},
   "source": [
    "## Import Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "873567be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.util import get_valid_uuid\n",
    "from uuid import uuid4\n",
    "\n",
    "blogs = client.collections.get(\"WeaviateBlogChunk\")\n",
    "\n",
    "for idx, blog_chunk in enumerate(blog_chunks):\n",
    "    upload = blogs.data.insert(\n",
    "        properties={\n",
    "            \"content\": blog_chunk\n",
    "        }\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
